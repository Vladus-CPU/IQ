{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler, DDIMScheduler\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Install required packages\n",
    "!pip install diffusers==0.31.0 transformers accelerate safetensors --upgrade\n",
    "# If you need to authenticate to HuggingFace:\n",
    "# from huggingface_hub import login\n",
    "# login()  # Insert your token if the model requires authentication\n",
    "\n",
    "print(\"Libraries installed and imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and set the tokenizer limits\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"Laxhar/noobai-XL-1.1\", \n",
    "    torch_dtype=torch.float16, \n",
    "    scheduler=EulerDiscreteScheduler.from_pretrained(\"Laxhar/noobai-XL-1.1\", subfolder=\"scheduler\"), \n",
    "    use_safetensors=True  # or False, depending on the repository\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Remove token length limits\n",
    "if pipe.tokenizer is not None:\n",
    "    pipe.tokenizer.model_max_length = 100000\n",
    "\n",
    "if hasattr(pipe, \"tokenizer_2\") and pipe.tokenizer_2 is not None:\n",
    "    pipe.tokenizer_2.model_max_length = 100000\n",
    "\n",
    "print(\"Pipeline loaded and tokenizer limits set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "set-sampler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set the diffusion sampler\n",
    "def set_diffusion_sampler(pipeline, sampler_name=\"euler\"):\n",
    "    sampler_name = sampler_name.lower().strip()\n",
    "    if sampler_name == \"euler\":\n",
    "        scheduler = EulerDiscreteScheduler.from_pretrained(\"Laxhar/noobai-XL-1.1\", subfolder=\"scheduler\")\n",
    "    elif sampler_name == \"ddim\":\n",
    "        scheduler = DDIMScheduler.from_pretrained(\"Laxhar/noobai-XL-1.1\", subfolder=\"scheduler\")\n",
    "    elif sampler_name == \"dpm\":\n",
    "        scheduler = DPMSolverMultistepScheduler.from_pretrained(\"Laxhar/noobai-XL-1.1\", subfolder=\"scheduler\")\n",
    "    else:\n",
    "        print(f\"Unknown sampler: {sampler_name}. Using EulerDiscreteScheduler by default.\")\n",
    "        scheduler = EulerDiscreteScheduler.from_pretrained(\"Laxhar/noobai-XL-1.1\", subfolder=\"scheduler\")\n",
    "\n",
    "    pipeline.scheduler = scheduler\n",
    "    print(f\"Sampler set to: {sampler_name}\")\n",
    "\n",
    "# Example call:\n",
    "set_diffusion_sampler(pipe, \"ddim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate images with different parameters\n",
    "def generate_image(\n",
    "    pipeline,\n",
    "    prompt,\n",
    "    negative_prompt=\"\",\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=7.5,\n",
    "    width=768,\n",
    "    height=768,\n",
    "    seed=42\n",
    "):\n",
    "    generator = torch.manual_seed(seed)\n",
    "\n",
    "    image = pipeline(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        generator=generator\n",
    "    ).images[0]\n",
    "\n",
    "    return image\n",
    "\n",
    "print(\"Image generation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hires-fix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder function for hires-fix / 8x NKMD-Superscale\n",
    "def hires_fix(image, scale_factor=2):\n",
    "    # Placeholder for hires-fix implementation\n",
    "    # Example if using an external library such as real_esrgan or BSRGAN:\n",
    "    # upsampler = RealESRGANer(\n",
    "    #     model_path='weights/RealESRGAN_x4plus.pth',\n",
    "    #     scale=4,\n",
    "    #     etc...\n",
    "    # )\n",
    "    # upscaled_image = upsampler.enhance(image, outscale=scale_factor)[0]\n",
    "\n",
    "    # Return the original image for now\n",
    "    return image\n",
    "\n",
    "print(\"Hires-fix function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the image generation function\n",
    "example_prompt = \"A beautiful futuristic cityscape at sunset, ultra-detailed\"\n",
    "negative_prompt = \"blurry, low quality\"\n",
    "steps = 30\n",
    "cfg = 7.0\n",
    "img_width = 512\n",
    "img_height = 512\n",
    "my_seed = 123\n",
    "\n",
    "result_image = generate_image(\n",
    "    pipeline=pipe,\n",
    "    prompt=example_prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_inference_steps=steps,\n",
    "    guidance_scale=cfg,\n",
    "    width=img_width,\n",
    "    height=img_height,\n",
    "    seed=my_seed\n",
    ")\n",
    "result_image.show()\n",
    "\n",
    "# Optional: Call hires-fix\n",
    "# result_image_upscaled = hires_fix(result_image, scale_factor=8)\n",
    "# result_image_upscaled.show()\n",
    "\n",
    "print(\"Image generation completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
