{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Image Generation with Laxhar/noobai-XL-1.1\n",
    "\n",
    "This notebook allows you to utilize the `Laxhar/noobai-XL-1.1` text-to-image model on Google Colab. You can customize various parameters such as sampler methods, sampling steps, seeds, CFG scale, image size, and apply a high-resolution fix.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup Environment](#1-Setup-Environment)\n",
    "2. [Import Libraries](#2-Import-Libraries)\n",
    "3. [Configure Device](#3-Configure-Device)\n",
    "4. [Modify Tokenizer Configuration](#4-Modify-Tokenizer-Configuration)\n",
    "5. [Load the Model](#5-Load-the-Model)\n",
    "6. [Define Helper Functions](#6-Define-Helper-Functions)\n",
    "7. [High-Resolution Fix (8x-NKMD-Superscale)](#7-High-Resolution-Fix-8x-NKMD-Superscale)\n",
    "8. [User Inputs](#8-User-Inputs)\n",
    "9. [Generate and Display Image](#9-Generate-and-Display-Image)\n",
    "10. [Save the Image](#10-Save-the-Image)\n",
    "11. [Summary](#11-Summary)\n",
    "12. [Additional Resources](#12-Additional-Resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup Environment\n",
    "\n",
    "First, install the necessary libraries required for running the model and processing images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install necessary libraries\n",
    "!pip install diffusers transformers accelerate scipy safetensors\n",
    "\n",
    "# Install additional libraries for high-resolution fixes\n",
    "!pip install k-diffusion"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Import Libraries\n",
    "\n",
    "Import all the necessary libraries for model loading, image processing, and setting configurations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler\n",
    "from transformers import CLIPTokenizer\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import k_diffusion as K\n",
    "from k_diffusion import sampling"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Configure Device\n",
    "\n",
    "Check if a GPU is available and set the device accordingly. GPUs significantly speed up model inference."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Modify Tokenizer Configuration\n",
    "\n",
    "To remove the character limit, we'll modify the tokenizer configurations by removing the `max_length` parameter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"Laxhar/noobai-XL-1.1\", use_fast=True)\n",
    "\n",
    "# Function to remove max_length from tokenizer config\n",
    "def remove_max_length(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    if 'max_length' in config:\n",
    "        del config['max_length']\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    print(f\"Removed 'max_length' from {config_path}\")\n",
    "\n",
    "# Paths to tokenizer configurations\n",
    "tokenizer_config_path = \"./tokenizer/tokenizer_config.json\"\n",
    "tokenizer_2_config_path = \"./tokenizer_2/tokenizer_config.json\"\n",
    "\n",
    "# Remove max_length from both tokenizer configs\n",
    "remove_max_length(tokenizer_config_path)\n",
    "remove_max_length(tokenizer_2_config_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Load the Model\n",
    "\n",
    "Load the scheduler and the Stable Diffusion XL Pipeline model. Enable memory-efficient attention for better performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the scheduler\n",
    "scheduler = EulerDiscreteScheduler.from_config(\"Laxhar/noobai-XL-1.1\")\n",
    "\n",
    "# Load the pipeline\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"Laxhar/noobai-XL-1.1\",\n",
    "    scheduler=scheduler,\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "# Enable memory-efficient attention if available\n",
    "try:\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    print(\"Enabled memory-efficient attention.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not enable memory-efficient attention: {e}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Define Helper Functions\n",
    "\n",
    "These functions will help set seeds for reproducibility and generate images based on user inputs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def generate_image(prompt, sampler=\"euler\", steps=50, seed=42, cfg_scale=7.5, image_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Generates an image based on the prompt and parameters.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Update scheduler if sampler is changed\n",
    "    if sampler.lower() == \"euler\":\n",
    "        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "    # Add other samplers here if needed\n",
    "    \n",
    "    # Generate image\n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=cfg_scale,\n",
    "        height=image_size[0],\n",
    "        width=image_size[1]\n",
    "    ).images[0]\n",
    "    \n",
    "    return image"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. High-Resolution Fix (8x-NKMD-Superscale)\n",
    "\n",
    "Apply a high-resolution fix to upscale the generated image. This implementation uses a placeholder for the `8x-NKMD-Superscale` method. Replace the placeholder with the actual superscaling method as needed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def hires_fix(image, scale=2.0, steps=50, seed=123):\n",
    "    \"\"\"\n",
    "    Applies a high-resolution fix to the image.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Placeholder for actual 8x-NKMD-Superscale implementation\n",
    "    # Replace the following code with the actual superscaling method\n",
    "    \n",
    "    # Example: Simple upscaling using PIL (replace with NKMD-Superscale)\n",
    "    upscaled_image = image.resize((int(image.width * scale), int(image.height * scale)), Image.LANCZOS)\n",
    "    \n",
    "    return upscaled_image"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. User Inputs\n",
    "\n",
    "Define the parameters for image generation. You can modify these values to customize the output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define user inputs\n",
    "prompt = \"A futuristic cityscape at sunset with flying cars\"\n",
    "sampler = \"euler\"              # Options: 'euler', 'other_samplers'\n",
    "steps = 50                     # Sampling steps\n",
    "seed = 42                      # Random seed for reproducibility\n",
    "cfg_scale = 7.5                # CFG scale for guidance\n",
    "image_size = (512, 512)        # Image size (height, width)\n",
    "\n",
    "# High-resolution fix parameters\n",
    "apply_hires = True             # Set to True to apply high-resolution fix\n",
    "scale = 2.0                    # Upscaling factor\n",
    "hires_steps = 50               # Steps for high-resolution fix\n",
    "hires_seed = 123               # Seed for high-resolution fix"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Generate and Display Image\n",
    "\n",
    "Generate the image based on the defined parameters and display it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate image\n",
    "image = generate_image(prompt, sampler, steps, seed, cfg_scale, image_size)\n",
    "\n",
    "# Apply high-resolution fix if enabled\n",
    "if apply_hires:\n",
    "    image = hires_fix(image, scale, hires_steps, hires_seed)\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Save the Image\n",
    "\n",
    "Save the generated image to the local file system."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save the generated image\n",
    "image_path = \"generated_image.png\"\n",
    "image.save(image_path)\n",
    "print(f\"Image saved to {image_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Summary\n",
    "\n",
    "- **Sampler Methods:** You can choose different sampler methods by modifying the `sampler` variable.\n",
    "- **Sampling Steps:** Adjust the `steps` variable to change the number of inference steps.\n",
    "- **Seeds:** Set the `seed` variable for reproducible results.\n",
    "- **CFG Scale:** Modify the `cfg_scale` variable to control the guidance scale.\n",
    "- **Image Size:** Change the `image_size` tuple to generate images of different dimensions.\n",
    "- **High-Resolution Fix:** Enable or disable high-resolution upscaling and adjust its parameters accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Additional Resources\n",
    "\n",
    "- [Hugging Face Diffusers Documentation](https://huggingface.co/docs/diffusers/index)\n",
    "- [Stable Diffusion Documentation](https://stability.ai/blog/stable-diffusion-public-release)\n",
    "- [K-Diffusion GitHub Repository](https://github.com/crowsonkb/k-diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note:** Ensure you have the necessary permissions and comply with the model's license terms when using and modifying it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
