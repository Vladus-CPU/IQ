{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "welcome_header"
      },
      "source": [
        "# Noobai-XL-1.1 Text-to-Image Generator\n",
        "\n",
        "This notebook allows you to use the Noobai-XL-1.1 model with various customization options including:\n",
        "- Different sampler methods\n",
        "- Adjustable sampling steps\n",
        "- Custom seeds\n",
        "- CFG scale control\n",
        "- Hi-res fix with 8x-NKMD-Superscale\n",
        "- Custom image size\n",
        "- Removed token length limitation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_dependencies"
      },
      "source": [
        "!pip install diffusers==0.21.4 transformers torch accelerate xformers gradio\n",
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip install controlnet_aux\n",
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "import_libraries"
      },
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, EulerAncestralDiscreteScheduler\n",
        "from diffusers import DDIMScheduler, LMSDiscreteScheduler, EulerDiscreteScheduler, PNDMScheduler\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load_model"
      },
      "source": [
        "def load_model():\n",
        "    model_id = \"Laxhar/noobai-XL-1.1\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None\n",
        "    )\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    return pipe\n",
        "\n",
        "pipe = load_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sampler_functions"
      },
      "source": [
        "SAMPLERS = {\n",
        "    \"DPM++ 2M\": DPMSolverMultistepScheduler,\n",
        "    \"Euler A\": EulerAncestralDiscreteScheduler,\n",
        "    \"DDIM\": DDIMScheduler,\n",
        "    \"LMS\": LMSDiscreteScheduler,\n",
        "    \"Euler\": EulerDiscreteScheduler,\n",
        "    \"PNDM\": PNDMScheduler\n",
        "}\n",
        "\n",
        "def change_sampler(pipe, sampler_name):\n",
        "    if sampler_name in SAMPLERS:\n",
        "        pipe.scheduler = SAMPLERS[sampler_name].from_config(pipe.scheduler.config)\n",
        "    return pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hires_upscaler"
      },
      "source": [
        "def apply_hires_fix(image, scale_factor, creativity_steps):\n",
        "    # 8x-NKMD-Superscale implementation\n",
        "    img_np = np.array(image)\n",
        "    \n",
        "    # Convert to YCrCb color space\n",
        "    img_ycrcb = cv2.cvtColor(img_np, cv2.COLOR_RGB2YCrCb)\n",
        "    \n",
        "    # Split channels\n",
        "    y, cr, cb = cv2.split(img_ycrcb)\n",
        "    \n",
        "    # Upscale Y channel\n",
        "    y_upscaled = cv2.resize(y, None, fx=scale_factor, fy=scale_factor, \n",
        "                           interpolation=cv2.INTER_LANCZOS4)\n",
        "    \n",
        "    # Apply sharpening based on creativity_steps\n",
        "    kernel = np.array([[-1,-1,-1],\n",
        "                      [-1, 9,-1],\n",
        "                      [-1,-1,-1]]) * (creativity_steps / 100)\n",
        "    y_upscaled = cv2.filter2D(y_upscaled, -1, kernel)\n",
        "    \n",
        "    # Upscale Cr and Cb channels\n",
        "    cr_upscaled = cv2.resize(cr, (y_upscaled.shape[1], y_upscaled.shape[0]), \n",
        "                            interpolation=cv2.INTER_LANCZOS4)\n",
        "    cb_upscaled = cv2.resize(cb, (y_upscaled.shape[1], y_upscaled.shape[0]), \n",
        "                            interpolation=cv2.INTER_LANCZOS4)\n",
        "    \n",
        "    # Merge channels\n",
        "    img_upscaled = cv2.merge([y_upscaled, cr_upscaled, cb_upscaled])\n",
        "    \n",
        "    # Convert back to RGB\n",
        "    img_upscaled = cv2.cvtColor(img_upscaled, cv2.COLOR_YCrCb2RGB)\n",
        "    \n",
        "    return Image.fromarray(img_upscaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generate_image"
      },
      "source": [
        "def generate_image(prompt, negative_prompt, sampler_name, steps, seed, cfg_scale, \n",
        "                  width, height, use_hires_fix, hires_scale, creativity_steps):\n",
        "    \n",
        "    # Set the seed if provided\n",
        "    if seed != -1:\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "    else:\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(np.random.randint(0, 2**32 - 1))\n",
        "    \n",
        "    # Change sampler\n",
        "    pipe = change_sampler(pipe, sampler_name)\n",
        "    \n",
        "    # Generate image\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=cfg_scale,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        generator=generator\n",
        "    ).images[0]\n",
        "    \n",
        "    # Apply hires fix if requested\n",
        "    if use_hires_fix:\n",
        "        image = apply_hires_fix(image, hires_scale, creativity_steps)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gradio_interface"
      },
      "source": [
        "def create_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                prompt = gr.Textbox(label=\"Prompt\", lines=3)\n",
        "                negative_prompt = gr.Textbox(label=\"Negative Prompt\", lines=3)\n",
        "                sampler = gr.Dropdown(\n",
        "                    choices=list(SAMPLERS.keys()),\n",
        "                    value=\"DPM++ 2M\",\n",
        "                    label=\"Sampler Method\"\n",
        "                )\n",
        "                steps = gr.Slider(minimum=1, maximum=150, value=30, step=1, label=\"Sampling Steps\")\n",
        "                seed = gr.Number(value=-1, label=\"Seed (-1 for random)\")\n",
        "                cfg = gr.Slider(minimum=1, maximum=20, value=7, step=0.5, label=\"CFG Scale\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    width = gr.Slider(minimum=256, maximum=2048, value=512, step=64, label=\"Width\")\n",
        "                    height = gr.Slider(minimum=256, maximum=2048, value=512, step=64, label=\"Height\")\n",
        "                \n",
        "                use_hires = gr.Checkbox(label=\"Use Hires Fix\")\n",
        "                with gr.Group() as hires_group:\n",
        "                    hires_scale = gr.Slider(minimum=1, maximum=4, value=2, step=0.5, label=\"Hires Scale\")\n",
        "                    creativity = gr.Slider(minimum=0, maximum=100, value=50, step=5, label=\"Creativity Steps\")\n",
        "                \n",
        "                generate_btn = gr.Button(\"Generate\")\n",
        "            \n",
        "            with gr.Column():\n",
        "                output = gr.Image(label=\"Generated Image\")\n",
        "        \n",
        "        generate_btn.click(\n",
        "            fn=generate_image,\n",
        "            inputs=[\n",
        "                prompt, negative_prompt, sampler, steps, seed, cfg,\n",
        "                width, height, use_hires, hires_scale, creativity\n",
        "            ],\n",
        "            outputs=output\n",
        "        )\n",
        "        \n",
        "        use_hires.change(\n",
        "            fn=lambda x: gr.Group.update(visible=x),\n",
        "            inputs=[use_hires],\n",
        "            outputs=[hires_group]\n",
        "        )\n",
        "    \n",
        "    return demo\n",
        "\n",
        "demo = create_interface()\n",
        "demo.launch(share=True, debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Noobai-XL-1.1_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
