{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Noobai-XL-1.1 Text-to-Image Generator\n",
        "\n",
        "This notebook implements the Noobai-XL-1.1 model with various customization options including:\n",
        "- Different sampler methods\n",
        "- Adjustable sampling steps\n",
        "- Custom seeds\n",
        "- CFG scale control\n",
        "- Image size control\n",
        "- HiRes fix with 8x-NKMD-Superscale"
      ],
      "metadata": {
        "id": "setup_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q diffusers==0.21.4 transformers==4.31.0 accelerate==0.21.0 xformers\n",
        "!pip install opencv-python basicsr facexlib gfpgan\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "install_dependencies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "from diffusers import DDIMScheduler, LMSDiscreteScheduler, EulerDiscreteScheduler, EulerAncestralDiscreteScheduler\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "\n",
        "# Initialize the model\n",
        "model_id = \"Laxhar/noobai-XL-1.1\"\n",
        "\n",
        "# Create pipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None\n",
        ")\n",
        "\n",
        "# Move to GPU and enable memory efficient attention\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# Remove token length limit\n",
        "pipe.tokenizer.model_max_length = 1000000\n",
        "\n",
        "# Dictionary of available samplers\n",
        "samplers = {\n",
        "    \"DPM++ 2M\": DPMSolverMultistepScheduler,\n",
        "    \"DDIM\": DDIMScheduler,\n",
        "    \"LMS\": LMSDiscreteScheduler,\n",
        "    \"Euler\": EulerDiscreteScheduler,\n",
        "    \"Euler a\": EulerAncestralDiscreteScheduler\n",
        "}\n",
        "\n",
        "def change_sampler(pipe, sampler_name):\n",
        "    if sampler_name in samplers:\n",
        "        pipe.scheduler = samplers[sampler_name].from_config(pipe.scheduler.config)\n",
        "    return pipe\n",
        "\n",
        "def superscale_image(img, scale_factor=4, creativity=1.0):\n",
        "    # Convert PIL Image to numpy array\n",
        "    img_np = np.array(img)\n",
        "    \n",
        "    # Calculate new dimensions\n",
        "    height, width = img_np.shape[:2]\n",
        "    new_height = int(height * scale_factor)\n",
        "    new_width = int(width * scale_factor)\n",
        "    \n",
        "    # Apply 8x-NKMD-Superscale-like upscaling\n",
        "    # Using a combination of Lanczos and detail enhancement\n",
        "    upscaled = cv2.resize(img_np, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
        "    \n",
        "    # Enhance details based on creativity parameter\n",
        "    if creativity > 0:\n",
        "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) * creativity\n",
        "        enhanced = cv2.filter2D(upscaled, -1, kernel)\n",
        "        upscaled = cv2.addWeighted(upscaled, 0.7, enhanced, 0.3, 0)\n",
        "    \n",
        "    return Image.fromarray(upscaled)\n",
        "\n",
        "def generate_image(prompt, negative_prompt, sampler_name, steps, cfg_scale, seed, \n",
        "                  width, height, use_hires_fix, hires_scale, hires_creativity):\n",
        "    # Set seed for reproducibility\n",
        "    if seed == -1:\n",
        "        seed = np.random.randint(0, 1000000)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "    \n",
        "    # Change sampler\n",
        "    pipe = change_sampler(pipe, sampler_name)\n",
        "    \n",
        "    # Generate image\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=cfg_scale,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        generator=generator\n",
        "    ).images[0]\n",
        "    \n",
        "    # Apply HiRes fix if selected\n",
        "    if use_hires_fix:\n",
        "        image = superscale_image(image, hires_scale, hires_creativity)\n",
        "    \n",
        "    return image, seed\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", lines=3)\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", lines=2)\n",
        "            sampler = gr.Dropdown(choices=list(samplers.keys()), value=\"DPM++ 2M\", label=\"Sampler\")\n",
        "            steps = gr.Slider(minimum=1, maximum=150, value=30, step=1, label=\"Sampling Steps\")\n",
        "            cfg = gr.Slider(minimum=1, maximum=20, value=7, step=0.5, label=\"CFG Scale\")\n",
        "            seed = gr.Number(value=-1, label=\"Seed (-1 for random)\")\n",
        "            width = gr.Slider(minimum=256, maximum=1024, value=512, step=64, label=\"Width\")\n",
        "            height = gr.Slider(minimum=256, maximum=1024, value=512, step=64, label=\"Height\")\n",
        "            \n",
        "            with gr.Accordion(\"HiRes Fix Settings\", open=False):\n",
        "                use_hires = gr.Checkbox(label=\"Enable HiRes Fix\", value=False)\n",
        "                hires_scale = gr.Slider(minimum=1, maximum=4, value=2, step=0.5, label=\"Scale Factor\")\n",
        "                hires_creativity = gr.Slider(minimum=0, maximum=2, value=1, step=0.1, label=\"Detail Enhancement\")\n",
        "            \n",
        "            generate_btn = gr.Button(\"Generate\")\n",
        "        \n",
        "        with gr.Column():\n",
        "            output_image = gr.Image(label=\"Generated Image\")\n",
        "            used_seed = gr.Number(label=\"Used Seed\", interactive=False)\n",
        "    \n",
        "    generate_btn.click(\n",
        "        fn=generate_image,\n",
        "        inputs=[prompt, negative_prompt, sampler, steps, cfg, seed, \n",
        "                width, height, use_hires, hires_scale, hires_creativity],\n",
        "        outputs=[output_image, used_seed]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "main_code"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
