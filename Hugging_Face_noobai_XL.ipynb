{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Image Generation with Laxhar/noobai-XL-1.1\n",
    "\n",
    "This notebook allows you to generate images from text prompts using the `Laxhar/noobai-XL-1.1` model. You can customize sampler methods, sampling steps, seeds, CFG scale, apply high-resolution fixes, and adjust image sizes."
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers diffusers accelerate\n",
    "!pip install --upgrade diffusers"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "from transformers import AutoTokenizer\n",
    "import IPython.display as display\n",
    "from PIL import Image"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and modify character limits\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Laxhar/noobai-XL-1.1\")\n",
    "tokenizer.model_max_length = 1024  # Remove or set to a higher limit\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"Laxhar/noobai-XL-1.1\", subfolder=\"tokenizer_2\")\n",
    "tokenizer_2.model_max_length = 1024  # Remove or set to a higher limit"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "prompt = \"A serene landscape with mountains and a river at sunset\"\n",
    "sampler = \"Euler\"  # Options: Euler, DDIM, etc.\n",
    "sampling_steps = 50\n",
    "seed = 42\n",
    "cfg_scale = 7.5\n",
    "image_size = (512, 512)\n",
    "hires_fix = True\n",
    "hires_scale = 2.0\n",
    "hires_steps = 20"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(seed)"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose sampler\n",
    "if sampler == \"Euler\":\n",
    "    scheduler = EulerDiscreteScheduler.from_config(\"Laxhar/noobai-XL-1.1\")\n",
    "elif sampler == \"DDIM\":\n",
    "    from diffusers import DDIMScheduler\n",
    "    scheduler = DDIMScheduler.from_config(\"Laxhar/noobai-XL-1.1\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported sampler method.\")"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pipeline\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"Laxhar/noobai-XL-1.1\",\n",
    "    scheduler=scheduler,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ").to(device)\n",
    "\n",
    "# Enable memory-efficient attention if possible\n",
    "pipeline.enable_attention_slicing()\n"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image\n",
    "with torch.autocast(device):\n",
    "    image = pipeline(\n",
    "        prompt,\n",
    "        num_inference_steps=sampling_steps,\n",
    "        guidance_scale=cfg_scale,\n",
    "        height=image_size[0],\n",
    "        width=image_size[1]\n",
    "    ).images[0]\n",
    "\n",
    "display.display(image)"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply high-resolution fix if enabled\n",
    "if hires_fix:\n",
    "    upscaled_image = image.resize((int(image_size[0]*hires_scale), int(image_size[1]*hires_scale)), Image.LANCZOS)\n",
    "    with torch.autocast(device):\n",
    "        upscaled_image = pipeline(\n",
    "            prompt,\n",
    "            num_inference_steps=hires_steps,\n",
    "            guidance_scale=cfg_scale,\n",
    "            height=upscaled_image.height,\n",
    "            width=upscaled_image.width,\n",
    "            init_image=upscaled_image,\n",
    "            strength=0.8\n",
    "        ).images[0]\n",
    "    display.display(upscaled_image)"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Parameters\n",
    "\n",
    "You can modify the parameters in the **Define parameters** section to customize your image generation."
  ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
