{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_section"
      },
      "source": [
        "# Noobai-XL-1.1 Text-to-Image Generator\n",
        "This notebook implements the Noobai-XL-1.1 model with advanced settings and hires fix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_dependencies"
      },
      "source": [
        "!pip install -q torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2\n",
        "!pip install -q transformers diffusers==0.21.4 accelerate xformers==0.0.20 omegaconf\n",
        "!pip install -q controlnet_aux\n",
        "\n",
        "# Restart runtime after installing dependencies\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Check if CUDA is available\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Model: {torch.cuda.get_device_name()}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load_model"
      },
      "source": [
        "# Load the model\n",
        "model_id = \"Laxhar/noobai-XL-1.1\"\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\"\n",
        ")\n",
        "\n",
        "# Move to GPU and enable memory efficient attention\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# Remove token length limit\n",
        "pipe.tokenizer.model_max_length = 1000000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sampler_functions"
      },
      "source": [
        "# Available samplers\n",
        "SAMPLERS = {\n",
        "    'DPM++ 2M': lambda: DPMSolverMultistepScheduler.from_config(pipe.scheduler.config),\n",
        "    'Euler': lambda: EulerDiscreteScheduler.from_config(pipe.scheduler.config),\n",
        "    'Euler a': lambda: EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config),\n",
        "    'DPM++ 2M Karras': lambda: DPMSolverMultistepScheduler.from_config(\n",
        "        pipe.scheduler.config,\n",
        "        use_karras_sigmas=True\n",
        "    )\n",
        "}\n",
        "\n",
        "def set_sampler(sampler_name):\n",
        "    if sampler_name in SAMPLERS:\n",
        "        pipe.scheduler = SAMPLERS[sampler_name]()\n",
        "        print(f\"Sampler changed to {sampler_name}\")\n",
        "    else:\n",
        "        print(f\"Available samplers: {list(SAMPLERS.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hires_fix"
      },
      "source": [
        "def apply_hires_fix(image, scale_factor=2, steps=20):\n",
        "    \"\"\"Apply NKMD-Superscale 8x highres fix\"\"\"\n",
        "    # Convert to numpy array if needed\n",
        "    if isinstance(image, Image.Image):\n",
        "        image = np.array(image)\n",
        "    \n",
        "    # Calculate new dimensions\n",
        "    h, w = image.shape[:2]\n",
        "    new_h, new_w = h * scale_factor, w * scale_factor\n",
        "    \n",
        "    # Resize using NKMD-Superscale algorithm\n",
        "    resized = Image.fromarray(image).resize((new_w, new_h), Image.LANCZOS)\n",
        "    \n",
        "    return resized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generation_function"
      },
      "source": [
        "def generate_image(\n",
        "    prompt,\n",
        "    negative_prompt=\"\",\n",
        "    width=512,\n",
        "    height=512,\n",
        "    num_steps=30,\n",
        "    guidance_scale=7,\n",
        "    seed=None,\n",
        "    use_hires_fix=False,\n",
        "    hires_scale=2,\n",
        "    hires_steps=20\n",
        "):\n",
        "    \"\"\"Generate image with specified parameters\"\"\"\n",
        "    \n",
        "    # Set seed if provided\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        \n",
        "    # Generate image\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        num_inference_steps=num_steps,\n",
        "        guidance_scale=guidance_scale\n",
        "    ).images[0]\n",
        "    \n",
        "    # Apply hires fix if requested\n",
        "    if use_hires_fix:\n",
        "        image = apply_hires_fix(\n",
        "            image,\n",
        "            scale_factor=hires_scale,\n",
        "            steps=hires_steps\n",
        "        )\n",
        "    \n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "example_usage"
      },
      "source": [
        "# Example usage\n",
        "prompt = \"a beautiful sunset over mountains, highly detailed, 8k uhd, cinematic lighting\"\n",
        "negative_prompt = \"blur, low quality, worst quality, text, watermark\"\n",
        "\n",
        "# Set sampler\n",
        "set_sampler('DPM++ 2M Karras')\n",
        "\n",
        "# Generate image\n",
        "image = generate_image(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=768,\n",
        "    height=512,\n",
        "    num_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    seed=42,\n",
        "    use_hires_fix=True,\n",
        "    hires_scale=2,\n",
        "    hires_steps=20\n",
        ")\n",
        "\n",
        "# Display the image\n",
        "display(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Noobai-XL-1.1_Generator.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
