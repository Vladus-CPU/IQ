{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text-to-Image Generation with NoobAI-XL-1.1\n",
        "This notebook demonstrates how to use the NoobAI-XL-1.1 model from Hugging Face for text-to-image generation with various customizable parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from huggingface_hub import login\n",
        "import json\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(token='YOUR_HUGGING_FACE_TOKEN')\n",
        "\n",
        "# Load the model\n",
        "model_id = 'Laxhar/noobai-XL-1.1'\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to('cuda')\n",
        "\n",
        "# Function to update tokenizer config\n",
        "def remove_tokenizer_limit(tokenizer_path):\n",
        "    with open(tokenizer_path, 'r') as file:\n",
        "        tokenizer_config = json.load(file)\n",
        "    tokenizer_config.pop('max_length', None)\n",
        "    with open(tokenizer_path, 'w') as file:\n",
        "        json.dump(tokenizer_config, file)\n",
        "\n",
        "# Update tokenizer configs\n",
        "remove_tokenizer_limit('tokenizer/tokenizer_config.json')\n",
        "remove_tokenizer_limit('tokenizer_2/tokenizer_config.json')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate images with customizable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def generate_image(prompt, sampler='pndm', steps=50, seed=42, cfg_scale=7.5, image_size=(512, 512), hires_fix=False):\n",
        "    generator = torch.manual_seed(seed)\n",
        "    if hires_fix:\n",
        "        pipe.scheduler = pipe.schedulers[sampler](pipe.model)\n",
        "        images = pipe(prompt, num_inference_steps=steps, guidance_scale=cfg_scale, generator=generator, height=image_size[0], width=image_size[1], hires_fix=True).images\n",
        "    else:\n",
        "        pipe.scheduler = pipe.schedulers[sampler](pipe.model)\n",
        "        images = pipe(prompt, num_inference_steps=steps, guidance_scale=cfg_scale, generator=generator, height=image_size[0], width=image_size[1]).images\n",
        "    return images[0]\n",
        "\n",
        "# Example usage\n",
        "prompt = 'A fantasy landscape with castles and dragons'\n",
        "image = generate_image(prompt, sampler='ddim', steps=100, seed=123, cfg_scale=10.0, image_size=(768, 768), hires_fix=True)\n",
        "image.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
