{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install diffusers transformers accelerate --upgrade\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone-repo-load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository and load the model from Hugging Face\n",
    "from huggingface_hub import login\n",
    "login('your_huggingface_token')  # Replace with your Hugging Face token\n",
    "\n",
    "# Load the model\n",
    "model_id = \"Laxhar/noobai-XL-1.1\"\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "\n",
    "# Move the pipeline to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    pipeline.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "update-tokenizer-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update tokenizer config to remove character limits\n",
    "import json\n",
    "\n",
    "def update_tokenizer_config(tokenizer_path):\n",
    "    config_file = os.path.join(tokenizer_path, 'tokenizer_config.json')\n",
    "    if os.path.exists(config_file):\n",
    "        with open(config_file, 'r') as file:\n",
    "            config = json.load(file)\n",
    "\n",
    "        # Remove limits if present\n",
    "        config.pop(\"max_length\", None)\n",
    "        config.pop(\"min_length\", None)\n",
    "\n",
    "        with open(config_file, 'w') as file:\n",
    "            json.dump(config, file, indent=4)\n",
    "\n",
    "update_tokenizer_config(os.path.join(model_id, 'tokenizer'))\n",
    "update_tokenizer_config(os.path.join(model_id, 'tokenizer_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-generate-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate images\n",
    "def generate_image(prompt, sampler_method=\"ddim\", sampling_steps=50, seed=42, cfg_scale=7.5, hires_fix=False, scale_creativity_steps=5, width=512, height=512):\n",
    "    \"\"\"\n",
    "    Function to generate images based on user inputs\n",
    "    Args:\n",
    "        prompt (str): Text prompt to generate image.\n",
    "        sampler_method (str): Sampling method to use (e.g., ddim, pndm, k_euler, etc.).\n",
    "        sampling_steps (int): Number of steps for sampling.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "        cfg_scale (float): Scale for guidance.\n",
    "        hires_fix (bool): Whether to apply high-resolution fix.\n",
    "        scale_creativity_steps (int): Steps for creativity adjustment in high-res mode.\n",
    "        width (int): Width of generated image.\n",
    "        height (int): Height of generated image.\n",
    "\n",
    "    Returns:\n",
    "        Image: Generated image.\n",
    "    \"\"\"\n",
    "    generator = torch.manual_seed(seed)\n",
    "\n",
    "    pipeline.sampler_method = sampler_method  # Adjust sampler method\n",
    "\n",
    "    # High-resolution fix\n",
    "    if hires_fix:\n",
    "        pipeline.scheduler.config.update({\"scale_creativity_steps\": scale_creativity_steps})\n",
    "\n",
    "    # Generate image\n",
    "    image = pipeline(\n",
    "        prompt,\n",
    "        num_inference_steps=sampling_steps,\n",
    "        guidance_scale=cfg_scale,\n",
    "        generator=generator,\n",
    "        width=width,\n",
    "        height=height\n",
    "    ).images[0]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from IPython.display import display\n",
    "image = generate_image(\n",
    "    prompt=\"A fantasy landscape with waterfalls and flying islands\",\n",
    "    sampler_method=\"k_euler\",\n",
    "    sampling_steps=100,\n",
    "    seed=1234,\n",
    "    cfg_scale=8.0,\n",
    "    hires_fix=True,\n",
    "    scale_creativity_steps=10,\n",
    "    width=768,\n",
    "    height=768\n",
    ")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image\n",
    "def save_image(image, path=\"/content/drive/MyDrive/generated_image.png\"):\n",
    "    image.save(path)\n",
    "\n",
    "save_image(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
