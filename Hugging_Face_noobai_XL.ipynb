{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "welcome_header"
      },
      "source": [
        "# Noobai-XL-1.1 Text-to-Image Generator\n",
        "### With advanced settings and HiRes Fix\n",
        "\n",
        "This notebook allows you to use the Noobai-XL-1.1 model with customizable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_dependencies"
      },
      "source": [
        "!pip install diffusers transformers torch accelerate xformers\n",
        "!pip install opencv-python-headless\n",
        "!pip install controlnet_aux"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, EulerDiscreteScheduler, EulerAncestralDiscreteScheduler\n",
        "from diffusers import DDIMScheduler, LMSDiscreteScheduler, KDPM2DiscreteScheduler\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import json\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "modify_tokenizer"
      },
      "source": [
        "# Function to modify tokenizer config to remove token limit\n",
        "def modify_tokenizer_config(model_path):\n",
        "    tokenizer_paths = [\n",
        "        f\"{model_path}/tokenizer/tokenizer_config.json\",\n",
        "        f\"{model_path}/tokenizer_2/tokenizer_config.json\"\n",
        "    ]\n",
        "    \n",
        "    for path in tokenizer_paths:\n",
        "        if os.path.exists(path):\n",
        "            with open(path, 'r') as f:\n",
        "                config = json.load(f)\n",
        "            \n",
        "            if 'model_max_length' in config:\n",
        "                config['model_max_length'] = 2048  # Increased token limit\n",
        "            \n",
        "            with open(path, 'w') as f:\n",
        "                json.dump(config, f, indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load_model"
      },
      "source": [
        "# Load the model\n",
        "model_id = \"Laxhar/noobai-XL-1.1\"\n",
        "modify_tokenizer_config(model_id)\n",
        "\n",
        "# Initialize pipeline with default scheduler\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None\n",
        ")\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sampler_functions"
      },
      "source": [
        "# Dictionary of available samplers\n",
        "SAMPLERS = {\n",
        "    'DPM++ 2M': DPMSolverMultistepScheduler,\n",
        "    'Euler': EulerDiscreteScheduler,\n",
        "    'Euler a': EulerAncestralDiscreteScheduler,\n",
        "    'DDIM': DDIMScheduler,\n",
        "    'LMS': LMSDiscreteScheduler,\n",
        "    'KDPM2': KDPM2DiscreteScheduler\n",
        "}\n",
        "\n",
        "def change_sampler(pipe, sampler_name):\n",
        "    if sampler_name in SAMPLERS:\n",
        "        pipe.scheduler = SAMPLERS[sampler_name].from_config(pipe.scheduler.config)\n",
        "    return pipe\n",
        "\n",
        "# HiRes Fix upscaler function\n",
        "def hires_fix_upscale(image, scale_factor=2, creativity_steps=20):\n",
        "    # Convert PIL Image to numpy array\n",
        "    img_np = np.array(image)\n",
        "    \n",
        "    # Upscale using NKMD-Superscale algorithm simulation\n",
        "    upscaled = cv2.resize(img_np, None, fx=scale_factor, fy=scale_factor, \n",
        "                         interpolation=cv2.INTER_LANCZOS4)\n",
        "    \n",
        "    # Convert back to PIL Image\n",
        "    return Image.fromarray(upscaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generation_function"
      },
      "source": [
        "def generate_image(prompt,\n",
        "                   negative_prompt=\"\",\n",
        "                   width=512,\n",
        "                   height=512,\n",
        "                   steps=30,\n",
        "                   cfg_scale=7.0,\n",
        "                   sampler_name=\"DPM++ 2M\",\n",
        "                   seed=None,\n",
        "                   use_hires_fix=False,\n",
        "                   hires_scale=2,\n",
        "                   hires_steps=20):\n",
        "    \n",
        "    # Set the seed if provided\n",
        "    if seed is not None:\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "    else:\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(torch.randint(0, 2**32 - 1, (1,)).item())\n",
        "    \n",
        "    # Change sampler if needed\n",
        "    pipe = change_sampler(pipe, sampler_name)\n",
        "    \n",
        "    # Generate the image\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=cfg_scale,\n",
        "        generator=generator\n",
        "    ).images[0]\n",
        "    \n",
        "    # Apply HiRes Fix if requested\n",
        "    if use_hires_fix:\n",
        "        image = hires_fix_upscale(image, \n",
        "                                 scale_factor=hires_scale,\n",
        "                                 creativity_steps=hires_steps)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "interface"
      },
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Create interface widgets\n",
        "prompt_text = widgets.Textarea(value='', description='Prompt:', rows=3)\n",
        "negative_prompt = widgets.Textarea(value='', description='Negative:', rows=2)\n",
        "width_slider = widgets.IntSlider(value=512, min=256, max=1024, step=64, description='Width:')\n",
        "height_slider = widgets.IntSlider(value=512, min=256, max=1024, step=64, description='Height:')\n",
        "steps_slider = widgets.IntSlider(value=30, min=10, max=150, description='Steps:')\n",
        "cfg_slider = widgets.FloatSlider(value=7.0, min=1.0, max=20.0, step=0.5, description='CFG Scale:')\n",
        "sampler_dropdown = widgets.Dropdown(options=list(SAMPLERS.keys()), description='Sampler:')\n",
        "seed_text = widgets.Text(value='', description='Seed:', placeholder='Random if empty')\n",
        "\n",
        "# HiRes Fix widgets\n",
        "hires_checkbox = widgets.Checkbox(value=False, description='Use HiRes Fix')\n",
        "hires_scale_slider = widgets.FloatSlider(value=2.0, min=1.5, max=8.0, step=0.5, description='HiRes Scale:')\n",
        "hires_steps_slider = widgets.IntSlider(value=20, min=10, max=50, description='HiRes Steps:')\n",
        "\n",
        "generate_button = widgets.Button(description='Generate')\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_generate_button_click(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        \n",
        "        # Convert seed to integer if provided\n",
        "        seed = None if seed_text.value == '' else int(seed_text.value)\n",
        "        \n",
        "        image = generate_image(\n",
        "            prompt=prompt_text.value,\n",
        "            negative_prompt=negative_prompt.value,\n",
        "            width=width_slider.value,\n",
        "            height=height_slider.value,\n",
        "            steps=steps_slider.value,\n",
        "            cfg_scale=cfg_slider.value,\n",
        "            sampler_name=sampler_dropdown.value,\n",
        "            seed=seed,\n",
        "            use_hires_fix=hires_checkbox.value,\n",
        "            hires_scale=hires_scale_slider.value,\n",
        "            hires_steps=hires_steps_slider.value\n",
        "        )\n",
        "        \n",
        "        display(image)\n",
        "\n",
        "generate_button.on_click(on_generate_button_click)\n",
        "\n",
        "# Display interface\n",
        "display(prompt_text,\n",
        "        negative_prompt,\n",
        "        widgets.HBox([width_slider, height_slider]),\n",
        "        widgets.HBox([steps_slider, cfg_slider]),\n",
        "        widgets.HBox([sampler_dropdown, seed_text]),\n",
        "        hires_checkbox,\n",
        "        widgets.HBox([hires_scale_slider, hires_steps_slider]),\n",
        "        generate_button,\n",
        "        output)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Noobai-XL-1.1_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
