{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# noobai-XL-1.1 Text-to-Image Model Setup\n",
        "\n",
        "This Colab notebook sets up the `noobai-XL-1.1` model for text-to-image generation with customizable settings. You can adjust sampler methods, sampling steps, seeds, CFG scale, image size, and apply the `hires fix 8x-NKMD-Superscale` for high-resolution outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers diffusers accelerate\n",
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip install --upgrade transformers\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "import transformers\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure the Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the model repository\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/Laxhar/noobai-XL-1.1\n",
        "\n",
        "# Modify tokenizer configuration to remove character limit\n",
        "!sed -i 's/\"max_length\": 77/\"max_length\": 1024/' noobai-XL-1.1/tokenizer/tokenizer_config.json\n",
        "!sed -i 's/\"max_length\": 77/\"max_length\": 1024/' noobai-XL-1.1/tokenizer_2/tokenizer_config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Model\n",
        "\n",
        "Set up the scheduler and load the Stable Diffusion pipeline with the modified tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Set up the scheduler\n",
        "scheduler = EulerAncestralDiscreteScheduler.from_pretrained(\"Laxhar/noobai-XL-1.1\", subfolder=\"scheduler\")\n",
        "\n",
        "# Load the pipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"Laxhar/noobai-XL-1.1\",\n",
        "    scheduler=scheduler,\n",
        "    revision=\"fp16\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True  # Make sure you have access to the model\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_image(prompt, sampler='euler', steps=50, seed=None, cfg_scale=7.5, image_size=(512, 512)):\n",
        "    \n",
        "    # Set the sampler\n",
        "    if sampler == 'euler':\n",
        "        scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "    elif sampler == 'ddim':\n",
        "        scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "    # Add more samplers if needed\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported sampler: {sampler}\")\n",
        "    \n",
        "    pipe.scheduler = scheduler\n",
        "    \n",
        "    # Set seed for reproducibility\n",
        "    if seed is not None:\n",
        "        generator = torch.Generator(device=device).manual_seed(seed)\n",
        "    else:\n",
        "        generator = None\n",
        "    \n",
        "    # Generate the image\n",
        "    with autocast(device):\n",
        "        image = pipe(\n",
        "            prompt,\n",
        "            num_inference_steps=steps,\n",
        "            guidance_scale=cfg_scale,\n",
        "            height=image_size[1],\n",
        "            width=image_size[0],\n",
        "            generator=generator\n",
        "        ).images[0]\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## High-Resolution Fix with 8x-NKMD-Superscale\n",
        "\n",
        "This section applies a high-resolution fix using the `8x-NKMD-Superscale` model. You can adjust the scale, creativity, and steps for the superscaling process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the SuperScale repository\n",
        "!git clone https://github.com/NKMD-Development/superscale-8x.git\n",
        "\n",
        "# Load the SuperScale model (modify as per actual model usage)\n",
        "# This is a placeholder for the actual SuperScale implementation\n",
        "# You may need to install specific dependencies or use a different library\n",
        "# For demonstration, we'll assume a simple upscale using PIL\n",
        "def superscale_image(image, scale=8, creativity=1.0, steps=10):\n",
        "    \n",
        "    # Placeholder for the actual SuperScale process\n",
        "    # Here we'll just resize the image as an example\n",
        "    new_size = (image.width * scale, image.height * scale)\n",
        "    upscaled_image = image.resize(new_size, Image.LANCZOS)\n",
        "    return upscaled_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User Inputs\n",
        "\n",
        "Set your desired parameters below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# User-configurable parameters\n",
        "prompt = \"A serene landscape with mountains and a river\"\n",
        "sampler = \"euler\"  # Options: 'euler', 'ddim'\n",
        "steps = 50\n",
        "seed = 42\n",
        "cfg_scale = 7.5\n",
        "image_size = (512, 512)\n",
        "\n",
        "# High-resolution fix parameters\n",
        "apply_superscale = True\n",
        "scale_factor = 8\n",
        "creativity = 1.0\n",
        "superscale_steps = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate and Display the Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=4096x4096 at 0x7F8C3C2E9C10>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate the image\n",
        "image = generate_image(\n",
        "    prompt=prompt,\n",
        "    sampler=sampler,\n",
        "    steps=steps,\n",
        "    seed=seed,\n",
        "    cfg_scale=cfg_scale,\n",
        "    image_size=image_size\n",
        ")\n",
        "\n",
        "# Apply high-resolution fix if enabled\n",
        "if apply_superscale:\n",
        "    image = superscale_image(\n",
        "        image,\n",
        "        scale=scale_factor,\n",
        "        creativity=creativity,\n",
        "        steps=superscale_steps\n",
        "    )\n",
        "\n",
        "# Display the image\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the image to the local filesystem\n",
        "output_path = \"generated_image.png\"\n",
        "image.save(output_path)\n",
        "print(f\"Image saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Resources\n",
        "\n",
        "- [Hugging Face Diffusers](https://huggingface.co/docs/diffusers/index)\n",
        "- [Stable Diffusion Documentation](https://huggingface.co/docs/diffusers/stable_diffusion)\n",
        "- [Transformers Documentation](https://huggingface.co/docs/transformers/index)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
