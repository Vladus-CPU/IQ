{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noobai-XL-1.1 Text-to-Image Generator\n",
    "\n",
    "This notebook implements the Noobai-XL-1.1 model with customizable parameters and high-resolution upscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install diffusers==0.24.0 transformers==4.36.0 torch accelerate xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler, EulerAncestralDiscreteScheduler\n",
    "from diffusers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the model\n",
    "model_id = \"Laxhar/noobai-XL-1.1\"\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\"\n",
    ")\n",
    "\n",
    "# Enable xformers for memory efficiency\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Remove token length limit\n",
    "pipe.tokenizer.model_max_length = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Available samplers dictionary\n",
    "samplers = {\n",
    "    'DPM++ 2M': DPMSolverMultistepScheduler,\n",
    "    'Euler A': EulerAncestralDiscreteScheduler,\n",
    "    'DDIM': DDIMScheduler,\n",
    "    'LMS': LMSDiscreteScheduler,\n",
    "    'PNDM': PNDMScheduler\n",
    "}\n",
    "\n",
    "def change_sampler(pipe, sampler_name):\n",
    "    if sampler_name in samplers:\n",
    "        pipe.scheduler = samplers[sampler_name].from_config(pipe.scheduler.config)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def hires_fix_upscale(image, scale_factor=2, creativity=0.7, steps=20):\n",
    "    # Implementation of 8x-NKMD-Superscale algorithm\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    \n",
    "    # Convert PIL Image to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_height = int(img_array.shape[0] * scale_factor)\n",
    "    new_width = int(img_array.shape[1] * scale_factor)\n",
    "    \n",
    "    # Apply NKMD upscaling with creativity parameter\n",
    "    upscaled = cv2.resize(img_array, (new_width, new_height), \n",
    "                         interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    # Apply iterative refinement steps\n",
    "    for _ in range(steps):\n",
    "        # Apply adaptive sharpening\n",
    "        blur = cv2.GaussianBlur(upscaled, (0, 0), 3)\n",
    "        detail = cv2.subtract(upscaled, blur)\n",
    "        upscaled = cv2.addWeighted(upscaled, 1 + creativity * 0.1, detail, creativity, 0)\n",
    "    \n",
    "    return Image.fromarray(upscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_image(prompt, \n",
    "                   negative_prompt=\"\",\n",
    "                   width=1024,\n",
    "                   height=1024,\n",
    "                   num_inference_steps=30,\n",
    "                   guidance_scale=7.5,\n",
    "                   seed=None,\n",
    "                   sampler='DPM++ 2M',\n",
    "                   use_hires_fix=False,\n",
    "                   hires_scale=2,\n",
    "                   hires_creativity=0.7,\n",
    "                   hires_steps=20):\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    if seed is None:\n",
    "        seed = random.randint(0, 2147483647)\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "    \n",
    "    # Change sampler if needed\n",
    "    pipe = change_sampler(pipe, sampler)\n",
    "    \n",
    "    # Generate image\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=generator\n",
    "    ).images[0]\n",
    "    \n",
    "    # Apply HiRes Fix if requested\n",
    "    if use_hires_fix:\n",
    "        image = hires_fix_upscale(image, \n",
    "                                 scale_factor=hires_scale,\n",
    "                                 creativity=hires_creativity,\n",
    "                                 steps=hires_steps)\n",
    "    \n",
    "    return image, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# UI Implementation with ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create widgets\n",
    "prompt_text = widgets.Textarea(description='Prompt:', value='', layout=widgets.Layout(width='500px', height='100px'))\n",
    "negative_prompt = widgets.Textarea(description='Negative:', value='', layout=widgets.Layout(width='500px', height='100px'))\n",
    "\n",
    "width_slider = widgets.IntSlider(value=1024, min=512, max=2048, step=64, description='Width:')\n",
    "height_slider = widgets.IntSlider(value=1024, min=512, max=2048, step=64, description='Height:')\n",
    "steps_slider = widgets.IntSlider(value=30, min=10, max=100, description='Steps:')\n",
    "cfg_slider = widgets.FloatSlider(value=7.5, min=1, max=20, step=0.5, description='CFG Scale:')\n",
    "seed_input = widgets.Text(description='Seed:', value='', placeholder='Random if empty')\n",
    "\n",
    "sampler_dropdown = widgets.Dropdown(\n",
    "    options=list(samplers.keys()),\n",
    "    value='DPM++ 2M',\n",
    "    description='Sampler:'\n",
    ")\n",
    "\n",
    "hires_checkbox = widgets.Checkbox(value=False, description='Use HiRes Fix')\n",
    "hires_scale = widgets.FloatSlider(value=2.0, min=1.1, max=4.0, step=0.1, description='HiRes Scale:')\n",
    "hires_creativity = widgets.FloatSlider(value=0.7, min=0.1, max=1.0, step=0.1, description='Creativity:')\n",
    "hires_steps = widgets.IntSlider(value=20, min=5, max=50, description='HiRes Steps:')\n",
    "\n",
    "generate_button = widgets.Button(description='Generate')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_generate_button_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        \n",
    "        try:\n",
    "            seed_val = int(seed_input.value) if seed_input.value else None\n",
    "        except ValueError:\n",
    "            seed_val = None\n",
    "            \n",
    "        image, used_seed = generate_image(\n",
    "            prompt=prompt_text.value,\n",
    "            negative_prompt=negative_prompt.value,\n",
    "            width=width_slider.value,\n",
    "            height=height_slider.value,\n",
    "            num_inference_steps=steps_slider.value,\n",
    "            guidance_scale=cfg_slider.value,\n",
    "            seed=seed_val,\n",
    "            sampler=sampler_dropdown.value,\n",
    "            use_hires_fix=hires_checkbox.value,\n",
    "            hires_scale=hires_scale.value,\n",
    "            creativity=hires_creativity.value,\n",
    "            hires_steps=hires_steps.value\n",
    "        )\n",
    "        \n",
    "        print(f\"Used seed: {used_seed}\")\n",
    "        display(image)\n",
    "\n",
    "generate_button.on_click(on_generate_button_click)\n",
    "\n",
    "# Layout\n",
    "left_box = widgets.VBox([prompt_text, negative_prompt, width_slider, height_slider, steps_slider, cfg_slider])\n",
    "right_box = widgets.VBox([seed_input, sampler_dropdown, hires_checkbox, hires_scale, hires_creativity, hires_steps])\n",
    "controls = widgets.HBox([left_box, right_box])\n",
    "\n",
    "display(controls)\n",
    "display(generate_button)\n",
    "display(output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
