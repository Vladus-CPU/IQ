{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mount-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "def mount_drive():\n",
    "    drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone-repo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository from Hugging Face\n",
    "!git clone https://huggingface.co/Laxhar/noobai-XL-1.1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install torch torchvision transformers diffusers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the model\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def load_model():\n",
    "    model_path = \"./noobai-XL-1.1\"\n",
    "\n",
    "    # Load the text-to-image pipeline\n",
    "    pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.float16\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Update tokenizers to remove limits\n",
    "    tokenizer_path = os.path.join(model_path, \"tokenizer\")\n",
    "    tokenizer_2_path = os.path.join(model_path, \"tokenizer_2\")\n",
    "\n",
    "    for path in [tokenizer_path, tokenizer_2_path]:\n",
    "        config_file = os.path.join(path, \"tokenizer_config.json\")\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = f.read()\n",
    "        config = config.replace(\"1024\", \"4096\")  # Increase limit\n",
    "        with open(config_file, \"w\") as f:\n",
    "            f.write(config)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ui-and-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UI for interacting with the model\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, Text, Dropdown\n",
    "from PIL import Image\n",
    "\n",
    "def generate_image(pipeline, prompt, steps, sampler, seed, cfg_scale, width, height, hires_scale, hires_steps):\n",
    "    from diffusers.schedulers import LMSDiscreteScheduler, DDIMScheduler, PNDMScheduler\n",
    "\n",
    "    # Configure sampler\n",
    "    if sampler == \"LMS\":\n",
    "        pipeline.scheduler = LMSDiscreteScheduler.from_config(pipeline.scheduler.config)\n",
    "    elif sampler == \"DDIM\":\n",
    "        pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n",
    "    elif sampler == \"PNDM\":\n",
    "        pipeline.scheduler = PNDMScheduler.from_config(pipeline.scheduler.config)\n",
    "\n",
    "    # Set seed\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    # Generate image\n",
    "    image = pipeline(\n",
    "        prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=cfg_scale,\n",
    "        width=width,\n",
    "        height=height\n",
    "    ).images[0]\n",
    "\n",
    "    if hires_scale:\n",
    "        from diffusers import ImageUpscaler\n",
    "\n",
    "        upscaler = ImageUpscaler.from_pretrained(\"8x-NKMD-Superscale\")\n",
    "        image = upscaler(image, steps=hires_steps, scale=hires_scale)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Interactive function\n",
    "pipeline = load_model()\n",
    "\n",
    "def interactive_demo():\n",
    "    interact(\n",
    "        lambda prompt, steps, sampler, seed, cfg_scale, width, height, hires_scale, hires_steps: generate_image(\n",
    "            pipeline, prompt, steps, sampler, seed, cfg_scale, width, height, hires_scale, hires_steps\n",
    "        ),\n",
    "        prompt=Text(description=\"Prompt\"),\n",
    "        steps=IntSlider(value=50, min=10, max=150, step=10, description=\"Steps\"),\n",
    "        sampler=Dropdown(options=[\"LMS\", \"DDIM\", \"PNDM\"], description=\"Sampler\"),\n",
    "        seed=IntSlider(value=42, min=0, max=1000, step=1, description=\"Seed\"),\n",
    "        cfg_scale=FloatSlider(value=7.5, min=1.0, max=20.0, step=0.5, description=\"CFG Scale\"),\n",
    "        width=IntSlider(value=512, min=256, max=1024, step=64, description=\"Width\"),\n",
    "        height=IntSlider(value=512, min=256, max=1024, step=64, description=\"Height\"),\n",
    "        hires_scale=FloatSlider(value=2.0, min=1.0, max=4.0, step=0.1, description=\"Hires Scale\"),\n",
    "        hires_steps=IntSlider(value=20, min=10, max=50, step=5, description=\"Hires Steps\"),\n",
    "    )\n",
    "\n",
    "# Start the interactive demo\n",
    "interactive_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
