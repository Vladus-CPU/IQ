{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "introduction"
      },
      "source": [
        "# üé® Noobai-XL-1.1 Text-to-Image Generator\n",
        "\n",
        "### –§—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª (Features):\n",
        "- –†—ñ–∑–Ω—ñ –º–µ—Ç–æ–¥–∏ —Å–µ–º–ø–ª—ñ–Ω–≥—É (Various sampling methods)\n",
        "- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫—Ä–æ–∫—ñ–≤ (Adjustable sampling steps)\n",
        "- –ö–æ–Ω—Ç—Ä–æ–ª—å seed (Seed control)\n",
        "- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è CFG Scale\n",
        "- HiRes Fix –∑ 8x-NKMD-Superscale\n",
        "- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (Image size control)\n",
        "- –ë–µ–∑ –æ–±–º–µ–∂–µ–Ω–Ω—è —Ç–æ–∫–µ–Ω—ñ–≤ (No token limit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_dependencies"
      },
      "source": [
        "!pip install diffusers==0.25.0 transformers==4.36.0 torch==2.1.0 accelerate\n",
        "!pip install xformers\n",
        "!pip install opencv-python-headless\n",
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline, AutoencoderKL, DDIMScheduler, DPMSolverMultistepScheduler\n",
        "from transformers import CLIPTokenizer\n",
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "model_setup"
      },
      "source": [
        "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ (Model loading)\n",
        "def load_model():\n",
        "    model_id = \"Laxhar/noobai-XL-1.1\"\n",
        "    \n",
        "    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –±–µ–∑ –ª—ñ–º—ñ—Ç—ñ–≤ (Setting up tokenizer without limits)\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(\n",
        "        model_id,\n",
        "        subfolder=\"tokenizer\",\n",
        "        use_fast=False,\n",
        "        model_max_length=512  # –ó–±—ñ–ª—å—à–µ–Ω–∏–π –ª—ñ–º—ñ—Ç —Ç–æ–∫–µ–Ω—ñ–≤\n",
        "    )\n",
        "\n",
        "    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–æ—ó –º–æ–¥–µ–ª—ñ (Loading main model)\n",
        "    pipe = DiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        variant=\"fp16\",\n",
        "        use_safetensors=True\n",
        "    )\n",
        "    \n",
        "    pipe = pipe.to(\"cuda\")\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    \n",
        "    return pipe\n",
        "\n",
        "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è HiRes Fix (HiRes Fix function)\n",
        "def apply_hires_fix(image, scale_factor, creativity_steps):\n",
        "    img_np = np.array(image)\n",
        "    height, width = img_np.shape[:2]\n",
        "    new_height = int(height * scale_factor)\n",
        "    new_width = int(width * scale_factor)\n",
        "    \n",
        "    # 8x-NKMD-Superscale implementation\n",
        "    for _ in range(creativity_steps):\n",
        "        img_np = cv2.resize(img_np, (new_width, new_height), \n",
        "                           interpolation=cv2.INTER_LANCZOS4)\n",
        "        # Advanced sharpening\n",
        "        kernel = np.array([[0, -1, 0],\n",
        "                          [-1, 5, -1],\n",
        "                          [0, -1, 0]])\n",
        "        img_np = cv2.filter2D(img_np, -1, kernel)\n",
        "    \n",
        "    return Image.fromarray(img_np)\n",
        "\n",
        "# –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó (Main generation function)\n",
        "def generate_image(prompt, negative_prompt, sampler, steps, seed, cfg_scale, \n",
        "                  width, height, use_hires, hires_scale, hires_steps):\n",
        "    if seed == -1:\n",
        "        seed = random.randint(0, 2147483647)\n",
        "    \n",
        "    # –í–∏–±—ñ—Ä —Å–µ–º–ø–ª–µ—Ä–∞ (Sampler selection)\n",
        "    if sampler == \"DDIM\":\n",
        "        pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "    elif sampler == \"DPM++ 2M\":\n",
        "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "    \n",
        "    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (Image generation)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=steps,\n",
        "        generator=generator,\n",
        "        guidance_scale=cfg_scale,\n",
        "        width=width,\n",
        "        height=height\n",
        "    ).images[0]\n",
        "    \n",
        "    # –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è HiRes Fix —è–∫—â–æ –≤–∏–±—Ä–∞–Ω–æ (Apply HiRes Fix if selected)\n",
        "    if use_hires:\n",
        "        image = apply_hires_fix(image, hires_scale, hires_steps)\n",
        "    \n",
        "    return image, seed\n",
        "\n",
        "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É Gradio (Creating Gradio interface)\n",
        "def create_interface():\n",
        "    with gr.Blocks() as interface:\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                prompt = gr.Textbox(label=\"Prompt\", lines=3)\n",
        "                negative_prompt = gr.Textbox(label=\"Negative Prompt\", lines=3)\n",
        "                \n",
        "                with gr.Row():\n",
        "                    sampler = gr.Dropdown([\"DDIM\", \"DPM++ 2M\"], label=\"Sampler\", value=\"DDIM\")\n",
        "                    steps = gr.Slider(1, 100, value=30, label=\"Steps\")\n",
        "                    \n",
        "                with gr.Row():\n",
        "                    seed = gr.Number(label=\"Seed (-1 for random)\", value=-1)\n",
        "                    cfg_scale = gr.Slider(1, 20, value=7, label=\"CFG Scale\")\n",
        "                    \n",
        "                with gr.Row():\n",
        "                    width = gr.Slider(128, 2048, value=512, step=64, label=\"Width\")\n",
        "                    height = gr.Slider(128, 2048, value=512, step=64, label=\"Height\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    use_hires = gr.Checkbox(label=\"Use HiRes Fix\")\n",
        "                    hires_scale = gr.Slider(1, 4, value=2, label=\"HiRes Scale\")\n",
        "                    hires_steps = gr.Slider(1, 10, value=3, label=\"HiRes Creativity Steps\")\n",
        "                \n",
        "                generate_btn = gr.Button(\"Generate\")\n",
        "                \n",
        "            with gr.Column():\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "                used_seed = gr.Number(label=\"Used Seed\", interactive=False)\n",
        "        \n",
        "        generate_btn.click(\n",
        "            fn=generate_image,\n",
        "            inputs=[prompt, negative_prompt, sampler, steps, seed, cfg_scale,\n",
        "                   width, height, use_hires, hires_scale, hires_steps],\n",
        "            outputs=[output_image, used_seed]\n",
        "        )\n",
        "    \n",
        "    return interface\n",
        "\n",
        "# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞ –∑–∞–ø—É—Å–∫ (Initialization and launch)\n",
        "pipe = load_model()\n",
        "interface = create_interface()\n",
        "interface.launch(share=True, debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Noobai-XL-1.1_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
