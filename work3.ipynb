{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vladus-CPU/IQ/blob/main/work3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oiJrPBwOiUP",
        "outputId": "2205e0dd-37da-4d82-b1ec-3b918d27c6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "accelerate 1.2.1 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.14.0 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-genai 0.3.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.14.0 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.14.0 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.29.0 which is incompatible.\n",
            "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet colorcet diffusers gradio hf-transfer huggingface-hub==0.14.0 matplotlib \\\n",
        "    numpy==1.23.5 opencv-contrib-python-headless pandas Pillow rich git+https://github.com/huggingface/pytorch-image-models.git@main#egg=timm \\\n",
        "    tokenizers torch>=2.1.0 torchvision transformers\n",
        "\n",
        "# При бажанні можете клонувати код з репозиторію, якщо він опублікований на GitHub,\n",
        "# або просто зкопіювати його у наступну комірку. Наведений нижче приклад показує,\n",
        "# як скопіювати файли безпосередньо:\n",
        "# !git clone https://github.com/user/wd-tagger-heatmap-example.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all required packages\n",
        "!pip install gradio torch torchvision timm huggingface_hub colorcet\n",
        "!pip install --upgrade gradio\n",
        "\n",
        "import gradio as gr\n",
        "import math\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "from typing import Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from huggingface_hub import hf_hub_download\n",
        "from huggingface_hub.utils import HfHubHTTPError\n",
        "from PIL import Image\n",
        "from torch import Tensor, nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import cv2\n",
        "import colorcet as cc\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "import timm\n",
        "from timm.data import create_transform, resolve_data_config\n",
        "from timm.models import VisionTransformer\n",
        "from torchvision import transforms as T\n",
        "import json\n",
        "import csv\n",
        "import io\n",
        "\n",
        "# ---------------------\n",
        "# BEGIN: common.py code\n",
        "# ---------------------\n",
        "\n",
        "@dataclass\n",
        "class Heatmap:\n",
        "    label: str\n",
        "    score: float\n",
        "    image: bytes  # Serialized image bytes\n",
        "\n",
        "@dataclass\n",
        "class LabelData:\n",
        "    names: list[str]\n",
        "    rating: list[np.int64]\n",
        "    general: list[np.int64]\n",
        "    character: list[np.int64]\n",
        "\n",
        "@dataclass\n",
        "class ImageLabels:\n",
        "    caption: str\n",
        "    booru: str\n",
        "    rating: dict[str, float]\n",
        "    general: dict[str, float]\n",
        "    character: dict[str, float]\n",
        "\n",
        "@lru_cache(maxsize=5)\n",
        "def load_labels_hf(repo_id: str, revision: Optional[str] = None, token: Optional[str] = None) -> LabelData:\n",
        "    try:\n",
        "        csv_path = hf_hub_download(\n",
        "            repo_id=repo_id,\n",
        "            filename=\"selected_tags.csv\",\n",
        "            revision=revision,\n",
        "            token=token\n",
        "        )\n",
        "        csv_path = Path(csv_path).resolve()\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"Error downloading selected_tags.csv from {repo_id}: {e}\")\n",
        "        return LabelData(names=[], rating=[], general=[], character=[])\n",
        "    df: pd.DataFrame = pd.read_csv(csv_path, usecols=[\"name\", \"category\"])\n",
        "    tag_data = LabelData(\n",
        "        names=df[\"name\"].tolist(),\n",
        "        rating=list(np.where(df[\"category\"] == 9)[0]),\n",
        "        general=list(np.where(df[\"category\"] == 0)[0]),\n",
        "        character=list(np.where(df[\"category\"] == 4)[0]),\n",
        "    )\n",
        "    return tag_data\n",
        "\n",
        "def pil_ensure_rgb(image: Image.Image) -> Image.Image:\n",
        "    if image.mode not in [\"RGB\", \"RGBA\"]:\n",
        "        image = image.convert(\"RGBA\") if \"transparency\" in image.info else image.convert(\"RGB\")\n",
        "    if image.mode == \"RGBA\":\n",
        "        canvas = Image.new(\"RGBA\", image.size, (255, 255, 255))\n",
        "        canvas.alpha_composite(image)\n",
        "        image = canvas.convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "def pil_pad_square(image: Image.Image, fill: tuple[int, int, int] = (255, 255, 255)) -> Image.Image:\n",
        "    w, h = image.size\n",
        "    px = max(image.size)\n",
        "    canvas = Image.new(\"RGB\", (px, px), fill)\n",
        "    canvas.paste(image, ((px - w) // 2, (px - h) // 2))\n",
        "    return canvas\n",
        "\n",
        "def preprocess_image(image: Image.Image, size_px: int | tuple[int, int], upscale: bool = True) -> Image.Image:\n",
        "    if isinstance(size_px, int):\n",
        "        size_px = (size_px, size_px)\n",
        "    image = pil_ensure_rgb(image)\n",
        "    image = pil_pad_square(image)\n",
        "    if image.size[0] < size_px[0] or image.size[1] < size_px[1]:\n",
        "        if not upscale:\n",
        "            raise ValueError(\"Image is smaller than target size, and upscaling is disabled\")\n",
        "        image = image.resize(size_px, Image.LANCZOS)\n",
        "    if image.size[0] > size_px[0] or image.size[1] > size_px[1]:\n",
        "        image.thumbnail(size_px, Image.BICUBIC)\n",
        "    return image\n",
        "\n",
        "def pil_make_grid(\n",
        "    images: list[Image.Image],\n",
        "    max_cols: int = 8,\n",
        "    padding: int = 4,\n",
        "    bg_color: tuple[int, int, int] = (40, 42, 54),\n",
        "    partial_rows: bool = True,\n",
        ") -> Image.Image:\n",
        "    if not images:\n",
        "        return Image.new(\"RGB\", (200, 200), bg_color)\n",
        "    n_cols = min(math.ceil(math.sqrt(len(images))), max_cols)\n",
        "    n_rows = math.ceil(len(images) / n_cols)\n",
        "    if n_cols * n_rows > len(images) and not partial_rows:\n",
        "        n_rows -= 1\n",
        "    image_width, image_height = images[0].size\n",
        "    canvas_width = ((image_width + padding) * n_cols) + padding\n",
        "    canvas_height = ((image_height + padding) * n_rows) + padding\n",
        "    canvas = Image.new(\"RGB\", (canvas_width, canvas_height), bg_color)\n",
        "    for i, img in enumerate(images):\n",
        "        x = (i % n_cols) * (image_width + padding) + padding\n",
        "        y = (i // n_cols) * (image_height + padding) + padding\n",
        "        canvas.paste(img, (x, y))\n",
        "    return canvas\n",
        "\n",
        "# ---------------------\n",
        "# END: common.py code\n",
        "# ---------------------\n",
        "\n",
        "# -----------------------\n",
        "# BEGIN: model.py code\n",
        "# -----------------------\n",
        "\n",
        "class RGBtoBGR(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if x.ndim == 4:\n",
        "            return x[:, [2, 1, 0], :, :]\n",
        "        return x[[2, 1, 0], :, :]\n",
        "\n",
        "model_cache: dict[str, VisionTransformer] = {}\n",
        "transform_cache: dict[str, T.Compose] = {}\n",
        "\n",
        "def model_device(model: nn.Module) -> torch.device:\n",
        "    return next(model.parameters()).device\n",
        "\n",
        "def load_model(repo_id: str) -> VisionTransformer:\n",
        "    global model_cache\n",
        "    if repo_id not in model_cache:\n",
        "        model_cache[repo_id] = timm.create_model(\"hf-hub:\" + repo_id, pretrained=True).eval().to(\n",
        "            torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        )\n",
        "    return model_cache[repo_id]\n",
        "\n",
        "def load_model_and_transform(repo_id: str) -> tuple[VisionTransformer, T.Compose]:\n",
        "    global transform_cache, model_cache\n",
        "    if repo_id not in model_cache:\n",
        "        model = timm.create_model(\"hf-hub:\" + repo_id, pretrained=True).eval()\n",
        "        model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "        model_cache[repo_id] = model\n",
        "    if repo_id not in transform_cache:\n",
        "        transforms = create_transform(**resolve_data_config(model.pretrained_cfg, model=model_cache[repo_id]))\n",
        "        transform_cache[repo_id] = T.Compose(transforms.transforms + [RGBtoBGR()])\n",
        "    return model_cache[repo_id], transform_cache[repo_id]\n",
        "\n",
        "def get_tags(probs: Tensor, labels: LabelData, gen_threshold: float, char_threshold: float):\n",
        "    if probs is None or not probs.numel():\n",
        "        return \"\", \"\", {}, {}, {}\n",
        "\n",
        "    probs_list = list(zip(labels.names, probs.numpy()))\n",
        "    rating_labels = {probs_list[i][0]: probs_list[i][1] for i in labels.rating}\n",
        "    gen_labels = {k: v for k, v in probs_list if v > gen_threshold and any(i in labels.general for i, _ in probs_list)}\n",
        "    char_labels = {k: v for k, v in probs_list if v > char_threshold and any(i in labels.character for i, _ in probs_list)}\n",
        "\n",
        "    combined_names = list(gen_labels.keys()) + list(char_labels.keys())\n",
        "    caption = \", \".join(combined_names) if combined_names else \"\"\n",
        "    booru = caption.replace(\"_\", \" \") if caption else \"\"\n",
        "\n",
        "    return caption, booru, rating_labels, char_labels, gen_labels\n",
        "\n",
        "@torch.no_grad()\n",
        "def render_heatmap(\n",
        "    image: Tensor,\n",
        "    gradients: Tensor,\n",
        "    image_feats: Tensor,\n",
        "    image_probs: Tensor,\n",
        "    image_labels: list[str],\n",
        "    cmap: LinearSegmentedColormap = cc.m_linear_bmy_10_95_c71,\n",
        "    image_size: tuple[int, int] = (448, 448),\n",
        "    font_args: dict = {\n",
        "        \"fontFace\": cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        \"fontScale\": 1,\n",
        "        \"color\": (255, 255, 255),\n",
        "        \"thickness\": 2,\n",
        "        \"lineType\": cv2.LINE_AA,\n",
        "    },\n",
        "    partial_rows: bool = True,\n",
        ") -> tuple[List[Heatmap], bytes]:\n",
        "    image_hmaps = gradients.mean(2, keepdim=True).mul(image_feats.unsqueeze(0)).squeeze()\n",
        "    hmap_dim = int(math.sqrt(image_hmaps.mean(-1).numel() / len(image_labels)))\n",
        "    image_hmaps = image_hmaps.mean(-1).reshape(len(image_labels), -1)\n",
        "    image_hmaps = image_hmaps[..., -hmap_dim**2:]\n",
        "    image_hmaps = image_hmaps.reshape(len(image_labels), hmap_dim, hmap_dim)\n",
        "    image_hmaps = image_hmaps.max(torch.zeros_like(image_hmaps))\n",
        "    image_hmaps /= image_hmaps.reshape(image_hmaps.shape[0], -1).max(-1)[0].unsqueeze(-1).unsqueeze(-1)\n",
        "    image_hmaps = torch.stack([(x - x.min()) / (x.max() - x.min() + 1e-8) for x in image_hmaps]).unsqueeze(1)\n",
        "    image_hmaps = F.interpolate(image_hmaps, size=image_size, mode=\"bilinear\").squeeze(1)\n",
        "\n",
        "    hmap_imgs = []\n",
        "    for tag, hmap, score in zip(image_labels, image_hmaps, image_probs.cpu()):\n",
        "        image_pixels = image.add(1).mul(127.5).squeeze().permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
        "        hmap_pixels = cmap(hmap.cpu().numpy(), bytes=True)[:, :, :3]\n",
        "        hmap_cv2 = cv2.cvtColor(hmap_pixels, cv2.COLOR_RGB2BGR)\n",
        "        hmap_image = cv2.addWeighted(image_pixels, 0.5, hmap_cv2, 0.5, 0)\n",
        "\n",
        "        if tag:\n",
        "            cv2.putText(hmap_image, tag, (10, 30), **font_args)\n",
        "            cv2.putText(hmap_image, f\"{score:.3f}\", (10, 60), **font_args)\n",
        "\n",
        "        hmap_pil = Image.fromarray(cv2.cvtColor(hmap_image, cv2.COLOR_BGR2RGB))\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        hmap_pil.save(img_byte_arr, format='PNG')\n",
        "        img_bytes = img_byte_arr.getvalue()\n",
        "\n",
        "        hmap_imgs.append(Heatmap(label=tag, score=score.item(), image=img_bytes))\n",
        "\n",
        "    hmap_imgs.sort(key=lambda x: x.score, reverse=True)\n",
        "    hmap_grid = pil_make_grid([Image.open(io.BytesIO(x.image)) for x in hmap_imgs], partial_rows=partial_rows)\n",
        "\n",
        "    grid_byte_arr = io.BytesIO()\n",
        "    hmap_grid.save(grid_byte_arr, format='PNG')\n",
        "    grid_bytes = grid_byte_arr.getvalue()\n",
        "\n",
        "    return hmap_imgs, grid_bytes\n",
        "\n",
        "def process_heatmap(\n",
        "    model: VisionTransformer,\n",
        "    image: Tensor,\n",
        "    labels: LabelData,\n",
        "    threshold: float = 0.5,\n",
        "    partial_rows: bool = True,\n",
        "):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.set_grad_enabled(True):\n",
        "        features = model.forward_features(image.to(device))\n",
        "        probs = model.forward_head(features)\n",
        "        if probs is not None:\n",
        "            probs = torch.sigmoid(probs).squeeze(0)\n",
        "            probs_mask = probs > threshold\n",
        "            heatmap_probs = probs[probs_mask]\n",
        "            label_indices = torch.nonzero(probs_mask, as_tuple=False).squeeze(1)\n",
        "            image_labels = [labels.names[i] for i in label_indices if i < len(labels.names)]\n",
        "            eye = torch.eye(heatmap_probs.shape[0], device=device)\n",
        "            grads = torch.autograd.grad(\n",
        "                outputs=heatmap_probs,\n",
        "                inputs=features,\n",
        "                grad_outputs=eye,\n",
        "                is_grads_batched=True,\n",
        "                retain_graph=True,\n",
        "            )\n",
        "            grads = grads[0].detach().requires_grad_(False)[:, 0, :, :].unsqueeze(1)\n",
        "        else:\n",
        "            print(\"Model output is None\")\n",
        "            return ([], b'', ImageLabels(\"\", \"\", {}, {}, {}), 0, \"CPU\")\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        if probs is not None:\n",
        "            hmap_imgs, hmap_grid = render_heatmap(\n",
        "                image=image,\n",
        "                gradients=grads,\n",
        "                image_feats=features,\n",
        "                image_probs=heatmap_probs,\n",
        "                image_labels=image_labels,\n",
        "                partial_rows=partial_rows,\n",
        "            )\n",
        "            caption, booru, rating_dict, character_dict, general_dict = get_tags(\n",
        "                probs=probs.cpu(),\n",
        "                labels=labels,\n",
        "                gen_threshold=threshold,\n",
        "                char_threshold=threshold,\n",
        "            )\n",
        "            total_time = time\n",
        "            time - start_time\n",
        "            device_type = \"GPU\" if torch.cuda.is_available() else \"CPU\"\n",
        "            image_labels_res = ImageLabels(caption, booru, rating_dict, general_dict, character_dict)\n",
        "        else:\n",
        "            hmap_imgs, hmap_grid = [], b''\n",
        "            image_labels_res = ImageLabels(\"\", \"\", {}, {}, {})\n",
        "            total_time = 0\n",
        "            device_type = \"CPU\"\n",
        "\n",
        "    return (hmap_imgs, hmap_grid, image_labels_res, total_time, device_type)\n",
        "\n",
        "# -----------------------\n",
        "# END: model.py code\n",
        "# -----------------------\n",
        "\n",
        "# -----------------------\n",
        "# BEGIN: app.py code\n",
        "# -----------------------\n",
        "from os import getenv\n",
        "from io import BytesIO\n",
        "\n",
        "# Application Metadata\n",
        "TITLE = \"WD Tagger Heatmap With Advanced Features\"\n",
        "DESCRIPTION = \"\"\"WD Tagger extended with batch processing, model comparison, searchable tags, exporting, and advanced customization.\"\"\"\n",
        "HF_TOKEN = getenv(\"HF_TOKEN\", None)\n",
        "\n",
        "# Available Models for Selection\n",
        "AVAILABLE_MODEL_REPOS = [\n",
        "    'SmilingWolf/wd-convnext-tagger-v3',\n",
        "    'SmilingWolf/wd-swinv2-tagger-v3',\n",
        "    'SmilingWolf/wd-vit-tagger-v3',\n",
        "    'SmilingWolf/wd-vit-large-tagger-v3',\n",
        "    \"SmilingWolf/wd-eva02-large-tagger-v3\",\n",
        "]\n",
        "DEFAULT_MODEL = \"SmilingWolf/wd-vit-tagger-v3\"\n",
        "WORK_DIR = Path(\".\").resolve()\n",
        "IMAGE_EXTENSIONS = [\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\", \".bmp\", \".tiff\", \".tif\"]\n",
        "\n",
        "# Example Images Placeholder (optional)\n",
        "example_images = []\n",
        "\n",
        "def predict_batch(\n",
        "    images: List[Image.Image],\n",
        "    model_repos: List[str],\n",
        "    threshold: float,\n",
        "    partial_rows: bool,\n",
        "    custom_gen_threshold: float,\n",
        "    custom_char_threshold: float,\n",
        "):\n",
        "    all_results = []\n",
        "    for img in images:\n",
        "        per_model_outputs = []\n",
        "        for repo in model_repos:\n",
        "            model, transform = load_model_and_transform(repo)\n",
        "            labels: LabelData = load_labels_hf(repo, token=HF_TOKEN)\n",
        "            processed_img = preprocess_image(img, (448, 448))\n",
        "            input_tensor = transform(processed_img).unsqueeze(0)\n",
        "\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model = model.to(device)\n",
        "            start_time = time.time()\n",
        "            try:\n",
        "                hmap_imgs, hmap_grid, image_labels_res, total_time, device_type = process_heatmap(\n",
        "                    model=model,\n",
        "                    image=input_tensor,\n",
        "                    labels=labels,\n",
        "                    threshold=threshold,\n",
        "                    partial_rows=partial_rows,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing model {repo}: {e}\")\n",
        "                continue\n",
        "\n",
        "            per_model_outputs.append({\n",
        "                \"model_repo\": repo,\n",
        "                \"heatmap_images\": hmap_imgs,\n",
        "                \"heatmap_grid\": hmap_grid,\n",
        "                \"caption\": image_labels_res.caption,\n",
        "                \"tags\": image_labels_res.booru,\n",
        "                \"rating\": image_labels_res.rating,\n",
        "                \"character\": image_labels_res.character,\n",
        "                \"general\": image_labels_res.general,\n",
        "                \"inference_time_s\": f\"{total_time:.2f}\",\n",
        "                \"device_type\": device_type\n",
        "            })\n",
        "        all_results.append(per_model_outputs)\n",
        "    return all_results\n",
        "\n",
        "def build_searchable_tags(results):\n",
        "    tag_set = set()\n",
        "    for img_res in results:\n",
        "        for model_res in img_res:\n",
        "            tag_set.update(model_res[\"general\"].keys())\n",
        "            tag_set.update(model_res[\"character\"].keys())\n",
        "    return sorted(list(tag_set))\n",
        "\n",
        "def export_csv_json(results):\n",
        "    csv_buffer = io.StringIO()\n",
        "    csv_writer = csv.writer(csv_buffer)\n",
        "    csv_writer.writerow([\"ImageIndex\", \"ModelRepo\", \"Caption\", \"Tags\", \"InferenceTime_s\", \"DeviceType\"])\n",
        "    for img_idx, img_res in enumerate(results):\n",
        "        for model_res in img_res:\n",
        "            csv_writer.writerow([\n",
        "                img_idx + 1,\n",
        "                model_res[\"model_repo\"],\n",
        "                model_res[\"caption\"],\n",
        "                model_res[\"tags\"],\n",
        "                model_res[\"inference_time_s\"],\n",
        "                model_res[\"device_type\"]\n",
        "            ])\n",
        "    csv_content = csv_buffer.getvalue()\n",
        "\n",
        "    json_content = json.dumps([model_res.__dict__ for img_res in results for model_res in img_res], default=lambda o: f\"<not serializable> {type(o)}\", indent=2)\n",
        "    return csv_content, json_content\n",
        "\n",
        "# Custom CSS for Styling\n",
        "css = \"\"\"\n",
        "#use_mcut, #char_mcut {\n",
        "    padding-top: var(--scale-3);\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Initialize Gradio Interface\n",
        "with gr.Blocks(theme=\"default\", analytics_enabled=False, title=TITLE, css=css) as demo:\n",
        "    gr.Markdown(f\"# {TITLE}\")\n",
        "    gr.Markdown(DESCRIPTION)\n",
        "\n",
        "    with gr.Tab(\"Main Inference\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                input_images = gr.Files(\n",
        "                    label=\"Upload Multiple Images\",\n",
        "                    file_types=[\"image\"],\n",
        "                    type=\"binary\",\n",
        "                    interactive=True\n",
        "                )\n",
        "                model_choices = gr.CheckboxGroup(\n",
        "                    choices=AVAILABLE_MODEL_REPOS,\n",
        "                    value=[DEFAULT_MODEL],\n",
        "                    label=\"Select one or more Models\"\n",
        "                )\n",
        "\n",
        "                threshold_slider = gr.Slider(0.0, 1.0, 0.35, 0.01, label=\"Base Threshold\")\n",
        "\n",
        "                partial_rows_toggle = gr.Checkbox(\n",
        "                    value=True, label=\"Allow Partial Rows in Heatmap Grid\"\n",
        "                )\n",
        "\n",
        "                custom_gen_threshold_slider = gr.Slider(\n",
        "                    0.0, 1.0, 0.35, 0.01, label=\"Custom General Tag Threshold\"\n",
        "                )\n",
        "                custom_char_threshold_slider = gr.Slider(\n",
        "                    0.0, 1.0, 0.35, 0.01, label=\"Custom Character Tag Threshold\"\n",
        "                )\n",
        "\n",
        "                run_button = gr.Button(\"Process\", variant=\"primary\")\n",
        "                export_button = gr.Button(\"Export Results as CSV & JSON\")\n",
        "                csv_output = gr.File(label=\"CSV Export\", file_count=\"single\")\n",
        "                json_output = gr.File(label=\"JSON Export\", file_count=\"single\")\n",
        "\n",
        "            with gr.Column():\n",
        "                result_data = gr.State([])\n",
        "\n",
        "                all_results_text = gr.Textbox(\n",
        "                    label=\"Consolidated Results (Textual)\",\n",
        "                    interactive=False,\n",
        "                    lines=20\n",
        "                )\n",
        "\n",
        "                heatmap_grid_output = gr.Image(\n",
        "                    label=\"Heatmap Grid\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                search_input = gr.Textbox(\n",
        "                    label=\"Search Tags\",\n",
        "                    placeholder=\"Enter text to filter detected tags\"\n",
        "                )\n",
        "                search_results = gr.Label(label=\"Matching Tags\")\n",
        "\n",
        "                def update_search(search_text, rdata):\n",
        "                    if not rdata:\n",
        "                        return \"No results loaded.\"\n",
        "                    all_tags = build_searchable_tags(rdata)\n",
        "                    filtered = [t for t in all_tags if search_text.lower() in t.lower()]\n",
        "                    if not filtered:\n",
        "                        return \"No matching tags found.\"\n",
        "                    return \", \".join(filtered)\n",
        "\n",
        "                search_input.change(\n",
        "                    update_search,\n",
        "                    inputs=[search_input, result_data],\n",
        "                    outputs=search_results\n",
        "                )\n",
        "\n",
        "        def run_inference_fn(files, model_repos, threshold, partial_rows, gen_thresh, char_thresh):\n",
        "            try:\n",
        "                if not files:\n",
        "                    return [], \"No images provided.\"\n",
        "\n",
        "                images = []\n",
        "                for file in files:\n",
        "                    try:\n",
        "                        image = Image.open(BytesIO(file))\n",
        "                        images.append(image)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing file {file}: {e}\")\n",
        "\n",
        "                if not images:\n",
        "                    return [], \"No valid images were uploaded.\"\n",
        "\n",
        "                results = predict_batch(images, model_repos, threshold, partial_rows, gen_thresh, char_thresh)\n",
        "\n",
        "                lines = []\n",
        "                for i, per_img in enumerate(results):\n",
        "                    lines.append(f\"Image {i + 1}:\")\n",
        "                    for pmodel in per_img:\n",
        "                        lines.append(f\"  Model: {pmodel['model_repo']} (Device: {pmodel['device_type']})\")\n",
        "                        lines.append(f\"    Inference Time: {pmodel['inference_time_s']} s\")\n",
        "                        lines.append(f\"    Tags: {pmodel['tags']}\")\n",
        "                        lines.append(f\"    Caption: {pmodel['caption']}\")\n",
        "                    lines.append(\"-----\")\n",
        "                textual_output = \"\\n\".join(lines)\n",
        "\n",
        "                if len(results) == 1 and len(results[0]) == 1:\n",
        "                    heatmap_grid_output.update(value=BytesIO(results[0][0][\"heatmap_grid\"]))\n",
        "                else:\n",
        "                    heatmap_grid_output.update(value=None)\n",
        "\n",
        "                return results, textual_output\n",
        "\n",
        "            except Exception as e:\n",
        "                error_message = f\"An unexpected error occurred: {str(e)}\"\n",
        "                print(error_message)\n",
        "                return [], error_message\n",
        "\n",
        "        run_button.click(\n",
        "            run_inference_fn,\n",
        "            inputs=[\n",
        "                input_images,\n",
        "                model_choices,\n",
        "                threshold_slider,\n",
        "                partial_rows_toggle,\n",
        "                custom_gen_threshold_slider,\n",
        "                custom_char_threshold_slider\n",
        "            ],\n",
        "            outputs=[result_data, all_results_text]\n",
        "        )\n",
        "\n",
        "        def export_results(rdata):\n",
        "            if not rdata:\n",
        "                return None, None\n",
        "            csv_content, json_content = export_csv_json(rdata)\n",
        "            csv_file = io.BytesIO(csv_content.encode(\"utf-8\"))\n",
        "            csv_file.name = \"results.csv\"\n",
        "            json_file = io.BytesIO(json_content.encode(\"utf-8\"))\n",
        "            json_file.name = \"results.json\"\n",
        "            return (csv_file, json_file)\n",
        "\n",
        "        export_button.click(\n",
        "            export_results,\n",
        "            inputs=[result_data],\n",
        "            outputs=[csv_output, json_output]\n",
        "        )\n",
        "\n",
        "    demo.queue(max_size=10)\n",
        "    demo.launch(share=True, debug=False)\n",
        "\n",
        "# -----------------------\n",
        "# END: app.py code\n",
        "# -----------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6AymO3FBOjVQ",
        "outputId": "bea18848-3519-4198-da4d-8b9d29ebc5a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.13.dev0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.1)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (11.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.10.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (11.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5613563c27ac0dee18.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5613563c27ac0dee18.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}